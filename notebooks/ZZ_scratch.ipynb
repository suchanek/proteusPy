{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZZ_scratch.ipynb - This is a general scratchpad used for code development and testing. Don't expect it to make a lot of sense.\n",
    "# Eric G. Suchanek, PhD. 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from proteusPy import Load_PDB_SS, Disulfide, DisulfideList, DisulfideLoader\n",
    "\n",
    "HOME = Path.home()\n",
    "PDB = Path(os.getenv(\"PDB\", HOME / \"pdb\"))\n",
    "\n",
    "MODEL_DIR = PDB/ \"good\"\n",
    "\n",
    "DATA_DIR = PDB / \"data\"\n",
    "SAVE_DIR = HOME / \"Documents\" / \"proteusPyDocs\" / \"classes\"\n",
    "REPO_DIR = HOME / \"repos\" / \"proteusPy\" / \"data\"\n",
    "\n",
    "OCTANT = SAVE_DIR / \"octant\"\n",
    "OCTANT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BINARY = SAVE_DIR / \"binary\"\n",
    "BINARY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEXTANT = SAVE_DIR / \"sextant\"\n",
    "SEXTANT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PBAR_COLS = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> load_PDB_SS(): Reading /Volumes/NeuroTunes/Users/suchanek/mambaforge/envs/ppydev/lib/python3.11/site-packages/proteusPy/data/PDB_SS_ALL_LOADER.pkl... \n",
      "-> load_PDB_SS(): Done reading /Volumes/NeuroTunes/Users/suchanek/mambaforge/envs/ppydev/lib/python3.11/site-packages/proteusPy/data/PDB_SS_ALL_LOADER.pkl... \n",
      "    =========== RCSB Disulfide Database Summary ==============\n",
      "       =========== Built: 2024-09-01 17:31:18 ==============\n",
      "PDB IDs present:                    36968\n",
      "Disulfides loaded:                  175521\n",
      "Average structure resolution:       2.07 Å\n",
      "Lowest Energy Disulfide:            2q7q_75D_140D\n",
      "Highest Energy Disulfide:           6vxk_801B_806B\n",
      "Cα distance cutoff:                 -1.00 Å\n",
      "Total RAM Used:                     44.32 GB.\n",
      "    ================= proteusPy: V0.97.5.20240901.dev1 =======================\n"
     ]
    }
   ],
   "source": [
    "PDB_SS = Load_PDB_SS(subset=False, verbose=True)\n",
    "PDB_SS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disulfide_secondary_structures(pdb_ss):\n",
    "    \"\"\"\n",
    "    Plot a graph of disulfide secondary structures segmented by secondary structure.\n",
    "\n",
    "    :param pdb_ss: The PDB_SS object containing SSList with disulfide bonds.\n",
    "    :type pdb_ss: object\n",
    "    \"\"\"\n",
    "    # Initialize counters for each secondary structure type\n",
    "    helix_count = 0\n",
    "    sheet_count = 0\n",
    "    turn_count = 0\n",
    "    nosecondary_count = 0\n",
    "\n",
    "    # Iterate through the SSList and count the secondary structures\n",
    "    for ss in pdb_ss.SSList:\n",
    "        proximal_secondary = ss.proximal_secondary\n",
    "        distal_secondary = ss.distal_secondary\n",
    "\n",
    "        if proximal_secondary == \"helix\":\n",
    "            helix_count += 1\n",
    "        elif proximal_secondary == \"sheet\":\n",
    "            sheet_count += 1\n",
    "        elif distal_secondary == \"turn\":\n",
    "            turn_count += 1\n",
    "        else:\n",
    "            nosecondary_count += 1\n",
    "\n",
    "    # Data for plotting\n",
    "    labels = ['Helix', 'Sheet', 'Turn', 'No Secondary']\n",
    "    counts = [helix_count, sheet_count, turn_count, nosecondary_count]\n",
    "\n",
    "    # Plotting the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, counts, color=['blue', 'green', 'red', 'gray'])\n",
    "    plt.xlabel('Secondary Structure')\n",
    "    plt.ylabel('Count of Disulfide Bonds')\n",
    "    plt.title('Disulfide Bonds Segmented by Secondary Structure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteusPy import extract_ssbonds_and_atoms\n",
    "from pathlib import Path\n",
    "import os\n",
    "verbose = True\n",
    "structure_fname = str(MODEL_DIR / \"pdb5rsa.ent\")\n",
    "ssbond_atom_list, num_ssbonds, errors = extract_ssbonds_and_atoms(\n",
    "        structure_fname, verbose=verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['helices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['sheets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['turns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['ssbonds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list['pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "fig = PDB_SS.plot_count_vs_class_df(\n",
    "    df,\n",
    "    title=\"Binary\",\n",
    "    save=True,\n",
    "    savedir=BINARY,\n",
    "    verbose=True,\n",
    "    base=2,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_eightclass_incidence(\n",
    "    theme=\"light\", save=True, verbose=True, savedir=OCTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_sixclass_incidence(\n",
    "    theme=\"light\", save=True, verbose=True, savedir=SEXTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clslist6 = PDB_SS.tclass.sslist_from_classid(\"55555\", base=6)\n",
    "clslist6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clslist8 = PDB_SS.tclass.sslist_from_classid(\"77778\", base=8)\n",
    "clslist8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = PDB_SS.tclass.classdf\n",
    "df6 = PDB_SS.tclass.sixclass_df\n",
    "df8 = PDB_SS.tclass.eightclass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_class_fromlist(loader: DisulfideLoader, sslist):\n",
    "    import pandas as pd\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for cls in sslist:\n",
    "        if cls is not None:\n",
    "            _y = loader.tclass.sslist_from_classid(cls)\n",
    "            # it's possible to have 0 SS in a class\n",
    "            if _y is not None:\n",
    "                # only append if we have both.\n",
    "                x.append(cls)\n",
    "                y.append(len(_y))\n",
    "\n",
    "    sslist_df = pd.DataFrame(columns=[\"class_id\", \"count\"])\n",
    "    sslist_df[\"class_id\"] = x\n",
    "    sslist_df[\"count\"] = y\n",
    "    return sslist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"00000\"\n",
    "sixcls = PDB_SS.tclass.binary_to_six_class(cls)\n",
    "df = enumerate_class_fromlist(PDB_SS, sixcls)\n",
    "# Assuming 'count' is the column by which we want to sort\n",
    "sorted_df = df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"00000\"\n",
    "eightcls = PDB_SS.tclass.binary_to_eight_class(cls)\n",
    "# eightcls\n",
    "\n",
    "df = enumerate_class_fromlist(PDB_SS, eightcls)\n",
    "# Assuming 'count' is the column by which we want to sort\n",
    "sorted_df = df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_eightclass_incidence(theme=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_count_vs_class_df(df, cls, theme=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_sixclass_incidence(light=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight = PDB_SS.tclass.eightclass_df\n",
    "eight.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist2 = PDB_SS.extract_class(\"87784\")\n",
    "sslist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_classes_vs_cutoff(0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdict = PDB_SS.SSDict\n",
    "ssdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ss_from_idlist(loader, idlist):\n",
    "    \"\"\"\n",
    "    Return a DisulfideList of Disulfides for a given list of PDBIDs\n",
    "\n",
    "    :param idlist: List of PDBIDs, e.g. ['4yys', '2q7q']\n",
    "    :return: DisulfideList\n",
    "    \"\"\"\n",
    "    res = DisulfideList([], \"RCSB_list\")\n",
    "    for k, v in loader.SSDict.items():\n",
    "        if k in idlist:\n",
    "            for ss_index in range(len(v)):\n",
    "                res.append(loader.SSList[v[ss_index]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = build_ss_from_idlist(PDB_SS, [\"4yys\", \"2q7q\"])\n",
    "sslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = PDB_SS[10:20]\n",
    "slice.pdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = PDB_SS.SSList\n",
    "slice2 = sslist[100:200]\n",
    "slice2.pdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tors = [-60, -60, 90, -60, -60]\n",
    "ss1 = Disulfide(torsions=tors)\n",
    "ss1.pprint_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = PDB_SS[\"2q7q_75D_140D\"]\n",
    "ss1.quiet = False\n",
    "ss1.bond_length_ideality\n",
    "ss1.bond_angle_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihed = ss1.dihedrals\n",
    "modelled_min = Disulfide(\"model\", quiet=False)\n",
    "modelled_min.dihedrals = dihed\n",
    "modelled_min.build_yourself()\n",
    "modelled_min.bond_length_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the distal N->Ca distance. 8/15/24 -egs-\n",
    "\n",
    "modelled_min.bond_angle_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = PDB_SS.SSList\n",
    "len(sslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_disulfide_dataframe(disulfide_list):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with columns PDB_ID, SS_Name, Angle_Deviation, Distance_Deviation\n",
    "    from a list of disulfides.\n",
    "\n",
    "    :param disulfide_list: List of disulfide objects.\n",
    "    :type proteusPy.DisulfideList: list\n",
    "    :return: DataFrame containing the disulfide information.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"PDB_ID\": [],\n",
    "        \"SS_Name\": [],\n",
    "        \"Angle_Deviation\": [],\n",
    "        \"Distance_Deviation\": [],\n",
    "        \"Ca_Distance\": [],\n",
    "    }\n",
    "\n",
    "    for ss in tqdm(disulfide_list, desc=\"Processing Disulfides\"):\n",
    "        pdb_id = ss.pdb_id\n",
    "        ca_distance = ss.ca_distance\n",
    "        angle_deviation = ss.bond_angle_ideality\n",
    "        distance_deviation = ss.bond_length_ideality\n",
    "\n",
    "        data[\"PDB_ID\"].append(pdb_id)\n",
    "        data[\"SS_Name\"].append(ss.name)\n",
    "        data[\"Angle_Deviation\"].append(angle_deviation)\n",
    "        data[\"Distance_Deviation\"].append(distance_deviation)\n",
    "        data[\"Ca_Distance\"].append(ca_distance)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a list of disulfide objects called disulfide_list\n",
    "# df = create_disulfide_dataframe(disulfide_list)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = create_disulfide_dataframe(sslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_histograms(df):\n",
    "    \"\"\"\n",
    "    Plot histograms for Distance_Deviation, Angle_Deviation, and Ca_Distance.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(21, 6))\n",
    "\n",
    "    # Distance Deviation Histogram\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(df[\"Distance_Deviation\"], kde=True, bins=30)\n",
    "    plt.title(\"Distance Deviation Distribution\")\n",
    "    plt.xlabel(\"Distance Deviation\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Angle Deviation Histogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.histplot(df[\"Angle_Deviation\"], kde=True, bins=30)\n",
    "    plt.title(\"Angle Deviation Distribution\")\n",
    "    plt.xlabel(\"Angle Deviation\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Ca_Distance Histogram\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.histplot(df[\"Ca_Distance\"], kde=True, bins=30)\n",
    "    plt.title(\"Ca Distance Distribution\")\n",
    "    plt.xlabel(\"Ca Distance\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_histograms(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def highlight_worst_structures(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Highlight the worst structures for distance and angle deviations and annotate their names.\n",
    "    Also, add a subplot showing the worst structures aggregated by PDB_ID.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    :param top_n: Number of worst structures to highlight.\n",
    "    :type top_n: int\n",
    "    \"\"\"\n",
    "    # Identify the worst structures for distance deviation\n",
    "    worst_distance = df.nlargest(top_n, \"Distance_Deviation\")\n",
    "\n",
    "    # Identify the worst structures for angle deviation\n",
    "    worst_angle = df.nlargest(top_n, \"Angle_Deviation\")\n",
    "\n",
    "    # Combine the worst structures\n",
    "    worst_structures = pd.concat([worst_distance, worst_angle]).drop_duplicates()\n",
    "\n",
    "    # Aggregate worst structures by PDB_ID\n",
    "    worst_structures_agg = (\n",
    "        worst_structures.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "    # Scatter plot for all structures\n",
    "    sns.scatterplot(\n",
    "        x=\"Distance_Deviation\",\n",
    "        y=\"Angle_Deviation\",\n",
    "        data=df,\n",
    "        label=\"All Structures\",\n",
    "        ax=axes[0],\n",
    "    )\n",
    "\n",
    "    # Highlight the worst structures\n",
    "    sns.scatterplot(\n",
    "        x=\"Distance_Deviation\",\n",
    "        y=\"Angle_Deviation\",\n",
    "        data=worst_structures,\n",
    "        color=\"red\",\n",
    "        label=\"Worst Structures\",\n",
    "        marker=\"X\",\n",
    "        s=100,\n",
    "        ax=axes[0],\n",
    "    )\n",
    "\n",
    "    # Annotate the worst structures with their names\n",
    "    for i, row in worst_structures.iterrows():\n",
    "        axes[0].annotate(\n",
    "            row[\"SS_Name\"],\n",
    "            (row[\"Distance_Deviation\"], row[\"Angle_Deviation\"]),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(5, 5),\n",
    "            ha=\"right\",\n",
    "        )\n",
    "\n",
    "    axes[0].set_title(\"Distance Deviation vs. Angle Deviation\")\n",
    "    axes[0].set_xlabel(\"Distance Deviation\")\n",
    "    axes[0].set_ylabel(\"Angle Deviation\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Bar plot for worst structures aggregated by PDB_ID\n",
    "    sns.barplot(x=\"PDB_ID\", y=\"Count\", data=worst_structures_agg, ax=axes[1])\n",
    "    axes[1].set_title(\"Worst Structures Aggregated by PDB_ID\")\n",
    "    axes[1].set_xlabel(\"PDB_ID\")\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def highlight_worst_structures2(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Highlight the worst structures for distance and angle deviations and annotate their names.\n",
    "    Also, add subplots showing the worst structures aggregated by PDB_ID for distance and angle deviations.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    :param top_n: Number of worst structures to highlight.\n",
    "    :type top_n: int\n",
    "    \"\"\"\n",
    "    # Identify the worst structures for distance deviation\n",
    "    worst_distance = df.nlargest(top_n, \"Distance_Deviation\")\n",
    "\n",
    "    # Identify the worst structures for angle deviation\n",
    "    worst_angle = df.nlargest(top_n, \"Angle_Deviation\")\n",
    "\n",
    "    # Combine the worst structures\n",
    "    worst_structures = pd.concat([worst_distance, worst_angle]).drop_duplicates()\n",
    "\n",
    "    # Aggregate worst structures by PDB_ID for distance and angle deviations\n",
    "    worst_distance_agg = (\n",
    "        worst_distance.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "    )\n",
    "    worst_angle_agg = worst_angle.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "    # Histogram for distance deviation\n",
    "    sns.histplot(df[\"Distance_Deviation\"], kde=True, bins=30, ax=axes[0])\n",
    "    axes[0].set_title(\"Distance Deviation Distribution\")\n",
    "    axes[0].set_xlabel(\"Distance Deviation\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Histogram for angle deviation\n",
    "    sns.histplot(df[\"Angle_Deviation\"], kde=True, bins=30, ax=axes[1])\n",
    "    axes[1].set_title(\"Angle Deviation Distribution\")\n",
    "    axes[1].set_xlabel(\"Angle Deviation\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Bar plots for worst structures aggregated by PDB_ID\n",
    "    sns.barplot(\n",
    "        x=\"PDB_ID\",\n",
    "        y=\"Count\",\n",
    "        data=worst_distance_agg,\n",
    "        ax=axes[2],\n",
    "        color=\"blue\",\n",
    "        label=\"Distance Deviation\",\n",
    "    )\n",
    "    sns.barplot(\n",
    "        x=\"PDB_ID\",\n",
    "        y=\"Count\",\n",
    "        data=worst_angle_agg,\n",
    "        ax=axes[2],\n",
    "        color=\"green\",\n",
    "        label=\"Angle Deviation\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    axes[2].set_title(\"Worst Structures Aggregated by PDB_ID\")\n",
    "    axes[2].set_xlabel(\"PDB_ID\")\n",
    "    axes[2].set_ylabel(\"Count\")\n",
    "    axes[2].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_worst_structures2(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_std_cutoff(df, column, num_std=2):\n",
    "    \"\"\"\n",
    "    Calculate cutoff based on standard deviation.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param column: Column name for which to calculate the cutoff.\n",
    "    :type column: str\n",
    "    :param num_std: Number of standard deviations to use for the cutoff.\n",
    "    :type num_std: int\n",
    "    :return: Cutoff value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    cutoff = mean + num_std * std\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def calculate_percentile_cutoff(df, column, percentile=95):\n",
    "    \"\"\"\n",
    "    Calculate cutoff based on percentile.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param column: Column name for which to calculate the cutoff.\n",
    "    :type column: str\n",
    "    :param percentile: Percentile to use for the cutoff.\n",
    "    :type percentile: int\n",
    "    :return: Cutoff value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    cutoff = np.percentile(df[column].dropna(), percentile)\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# distance_cutoff = calculate_percentile_cutoff(dev_df, 'Distance_Deviation', percentile=95)\n",
    "# angle_cutoff = calculate_percentile_cutoff(dev_df, 'Angle_Deviation', percentile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame named dev_df with columns 'Distance_Deviation' and 'Angle_Deviation'\n",
    "\n",
    "# Standard Deviation Method\n",
    "distance_cutoff_std = calculate_std_cutoff(dev_df, \"Distance_Deviation\", num_std=3)\n",
    "angle_cutoff_std = calculate_std_cutoff(dev_df, \"Angle_Deviation\", num_std=3)\n",
    "ca_cutoff_std = calculate_std_cutoff(dev_df, \"Ca_Distance\", num_std=3)\n",
    "\n",
    "# Percentile Method\n",
    "distance_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Distance_Deviation\", percentile=98\n",
    ")\n",
    "angle_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Angle_Deviation\", percentile=98\n",
    ")\n",
    "ca_cutoff_percentile = calculate_percentile_cutoff(dev_df, \"Ca_Distance\", percentile=98)\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (3 Std Dev): {distance_cutoff_std}\")\n",
    "print(f\"Angle Deviation Cutoff (3 Std Dev): {angle_cutoff_std}\")\n",
    "print(f\"Ca Distance Cutoff (3 Std Dev): {ca_cutoff_std}\\n\")\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (98th Percentile): {distance_cutoff_percentile}\")\n",
    "print(f\"Angle Deviation Cutoff (98th Percentile): {angle_cutoff_percentile}\")\n",
    "print(f\"Ca Distance Cutoff (98th Percentile): {ca_cutoff_percentile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_by_cutoffs(df, distance_cutoff, angle_cutoff):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame based on distance and angle cutoffs.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param distance_cutoff: Cutoff value for distance deviation.\n",
    "    :type distance_cutoff: float\n",
    "    :param angle_cutoff: Cutoff value for angle deviation.\n",
    "    :type angle_cutoff: float\n",
    "    :return: Filtered DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    filtered_df = df[\n",
    "        (df[\"Distance_Deviation\"] <= distance_cutoff)\n",
    "        & (df[\"Angle_Deviation\"] <= angle_cutoff)\n",
    "    ]\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# distance_cutoff = 5.0\n",
    "# angle_cutoff = 10.0\n",
    "# filtered_df = filter_by_cutoffs(dev_df, distance_cutoff, angle_cutoff)\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = filter_by_cutoffs(dev_df, 1.0, 10.0)\n",
    "filt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_df[\"Angle_Deviation\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_std_cutoff(df, column, num_std=2):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    cutoff = mean + num_std * std\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def calculate_percentile_cutoff(df, column, percentile=95):\n",
    "    cutoff = np.percentile(df[column].dropna(), percentile)\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "# Assuming you have a DataFrame named dev_df with columns 'Distance_Deviation' and 'Angle_Deviation'\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"Missing values in 'Angle_Deviation': {dev_df['Angle_Deviation'].isna().sum()}\")\n",
    "\n",
    "# Drop missing values for the calculation\n",
    "dev_df = dev_df.dropna(subset=[\"Angle_Deviation\", \"Distance_Deviation\"])\n",
    "\n",
    "# Standard Deviation Method\n",
    "distance_cutoff_std = calculate_std_cutoff(dev_df, \"Distance_Deviation\", num_std=3)\n",
    "angle_cutoff_std = calculate_std_cutoff(dev_df, \"Angle_Deviation\", num_std=3)\n",
    "\n",
    "# Percentile Method\n",
    "distance_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Distance_Deviation\", percentile=98\n",
    ")\n",
    "angle_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Angle_Deviation\", percentile=98\n",
    ")\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (3 Std Dev): {distance_cutoff_std}\")\n",
    "print(f\"Angle Deviation Cutoff (3 Std Dev): {angle_cutoff_std}\")\n",
    "print(f\"Distance Deviation Cutoff (98th Percentile): {distance_cutoff_percentile}\")\n",
    "print(f\"Angle Deviation Cutoff (98th Percentile): {angle_cutoff_percentile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppydev (V0.97.5.20240901.dev0)",
   "language": "python",
   "name": "ppydev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
