{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZZ_scratch.ipynb - This is a general scratchpad used for code development and testing. Don't expect it to make a lot of sense.\n",
    "# Eric G. Suchanek, PhD. 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from proteusPy import (\n",
    "    Load_PDB_SS,\n",
    "    Disulfide,\n",
    "    DisulfideList,\n",
    "    DisulfideLoader,\n",
    "    torsion_to_class_string,\n",
    ")\n",
    "\n",
    "from proteusPy.ProteusGlobals import *\n",
    "\n",
    "HOME = Path.home()\n",
    "PDB = Path(os.getenv(\"PDB\", HOME / \"pdb\"))\n",
    "\n",
    "MODEL_DIR = PDB / \"good\"\n",
    "\n",
    "PDB_DATA_DIR = PDB / \"data\"\n",
    "SAVE_DIR = HOME / \"Documents\" / \"proteusPyDocs\" / \"classes\"\n",
    "REPO_DIR = HOME / \"repos\" / \"proteusPy\" / \"data\"\n",
    "\n",
    "OCTANT = SAVE_DIR / \"octant\"\n",
    "OCTANT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BINARY = SAVE_DIR / \"binary\"\n",
    "BINARY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEXTANT = SAVE_DIR / \"sextant\"\n",
    "SEXTANT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PBAR_COLS = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> load_PDB_SS(): Reading /Users/egs/miniforge3/envs/ppydev/lib/python3.11/site-packages/proteusPy/data/PDB_SS_ALL_LOADER.pkl... \n",
      "-> load_PDB_SS(): Done Reading /Users/egs/miniforge3/envs/ppydev/lib/python3.11/site-packages/proteusPy/data/PDB_SS_ALL_LOADER.pkl... \n"
     ]
    }
   ],
   "source": [
    "pdb = Load_PDB_SS(verbose=True, subset=False, cutoff=8.0, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pdb.getTorsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def Nbuild_torsion_df(ss_list, quiet) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe containing the input DisulfideList torsional parameters,\n",
    "    Cα-Cα distance, energy, and phi-psi angles. This can take several minutes for the\n",
    "    entire database.\n",
    "\n",
    "    :return: pd.DataFrame containing the torsions\n",
    "    \"\"\"\n",
    "    # create a dictionary to collect rows as dictionaries\n",
    "    rows = {}\n",
    "    i = 0\n",
    "    total_length = len(ss_list)\n",
    "    update_interval = max(1, total_length // 20)  # 5% of the list length\n",
    "\n",
    "    sslist = ss_list\n",
    "    if quiet:\n",
    "        pbar = sslist\n",
    "    else:\n",
    "        pbar = tqdm(sslist, ncols=PBAR_COLS, leave=False)\n",
    "\n",
    "    for ss in pbar:\n",
    "        new_row = {\n",
    "            \"source\": ss.pdb_id,\n",
    "            \"ss_id\": ss.name,\n",
    "            \"proximal\": ss.proximal,\n",
    "            \"distal\": ss.distal,\n",
    "            \"chi1\": ss.chi1,\n",
    "            \"chi2\": ss.chi2,\n",
    "            \"chi3\": ss.chi3,\n",
    "            \"chi4\": ss.chi4,\n",
    "            \"chi5\": ss.chi5,\n",
    "            \"energy\": ss.energy,\n",
    "            \"ca_distance\": ss.ca_distance,\n",
    "            \"cb_distance\": ss.cb_distance,\n",
    "            \"psiprox\": ss.psiprox,\n",
    "            \"phiprox\": ss.phiprox,\n",
    "            \"phidist\": ss.phidist,\n",
    "            \"psidist\": ss.psidist,\n",
    "            \"torsion_length\": ss.torsion_length,\n",
    "            \"rho\": ss.rho,\n",
    "        }\n",
    "        rows[i] = new_row\n",
    "        i += 1\n",
    "\n",
    "        if not quiet:\n",
    "            if i % update_interval == 0 or i == total_length - 1:\n",
    "                pbar.update(update_interval)\n",
    "\n",
    "    if not quiet:\n",
    "        pbar.close()\n",
    "\n",
    "    # Convert the dictionary values to a list of dictionaries\n",
    "    rows_array = list(rows.values())\n",
    "\n",
    "    # create the dataframe from the list of dictionaries\n",
    "    SS_df = pd.DataFrame(\n",
    "        rows_array,\n",
    "        columns=[\n",
    "            \"source\",\n",
    "            \"ss_id\",\n",
    "            \"proximal\",\n",
    "            \"distal\",\n",
    "            \"chi1\",\n",
    "            \"chi2\",\n",
    "            \"chi3\",\n",
    "            \"chi4\",\n",
    "            \"chi5\",\n",
    "            \"energy\",\n",
    "            \"ca_distance\",\n",
    "            \"cb_distance\",\n",
    "            \"psiprox\",\n",
    "            \"phiprox\",\n",
    "            \"phidist\",\n",
    "            \"psidist\",\n",
    "            \"torsion_length\",\n",
    "            \"rho\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return SS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = pdb.SSList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proximal</th>\n",
       "      <th>distal</th>\n",
       "      <th>chi1</th>\n",
       "      <th>chi2</th>\n",
       "      <th>chi3</th>\n",
       "      <th>chi4</th>\n",
       "      <th>chi5</th>\n",
       "      <th>energy</th>\n",
       "      <th>ca_distance</th>\n",
       "      <th>cb_distance</th>\n",
       "      <th>psiprox</th>\n",
       "      <th>phiprox</th>\n",
       "      <th>phidist</th>\n",
       "      <th>psidist</th>\n",
       "      <th>torsion_length</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.0</td>\n",
       "      <td>175521.0</td>\n",
       "      <td>175521.0</td>\n",
       "      <td>175521.0</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>228.122868</td>\n",
       "      <td>275.877217</td>\n",
       "      <td>-45.297774</td>\n",
       "      <td>-5.662176</td>\n",
       "      <td>-4.160864</td>\n",
       "      <td>-23.030203</td>\n",
       "      <td>-30.380421</td>\n",
       "      <td>3.736533</td>\n",
       "      <td>5.684791</td>\n",
       "      <td>3.930672</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>232.946064</td>\n",
       "      <td>-0.172521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>323.592452</td>\n",
       "      <td>327.258222</td>\n",
       "      <td>104.225509</td>\n",
       "      <td>108.937131</td>\n",
       "      <td>94.110093</td>\n",
       "      <td>111.367245</td>\n",
       "      <td>99.629063</td>\n",
       "      <td>2.495097</td>\n",
       "      <td>1.888242</td>\n",
       "      <td>2.109342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.621923</td>\n",
       "      <td>8.358270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-86.000000</td>\n",
       "      <td>-62.000000</td>\n",
       "      <td>-179.999869</td>\n",
       "      <td>-179.999596</td>\n",
       "      <td>-179.981757</td>\n",
       "      <td>-179.999698</td>\n",
       "      <td>-179.999497</td>\n",
       "      <td>0.491737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>77.516159</td>\n",
       "      <td>-179.997832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>-92.733156</td>\n",
       "      <td>-87.410534</td>\n",
       "      <td>-87.982527</td>\n",
       "      <td>-97.168156</td>\n",
       "      <td>-74.993066</td>\n",
       "      <td>1.969126</td>\n",
       "      <td>5.160189</td>\n",
       "      <td>3.688707</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>185.221894</td>\n",
       "      <td>-1.093180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>-64.311525</td>\n",
       "      <td>-54.581797</td>\n",
       "      <td>-65.014330</td>\n",
       "      <td>-66.344415</td>\n",
       "      <td>-59.669380</td>\n",
       "      <td>3.189497</td>\n",
       "      <td>5.714554</td>\n",
       "      <td>3.846127</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>231.983589</td>\n",
       "      <td>0.015960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>-38.734403</td>\n",
       "      <td>96.058493</td>\n",
       "      <td>92.824530</td>\n",
       "      <td>82.464225</td>\n",
       "      <td>56.393666</td>\n",
       "      <td>4.595320</td>\n",
       "      <td>6.268357</td>\n",
       "      <td>4.025268</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>272.324025</td>\n",
       "      <td>1.079960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8025.000000</td>\n",
       "      <td>9004.000000</td>\n",
       "      <td>179.999973</td>\n",
       "      <td>179.998744</td>\n",
       "      <td>179.994824</td>\n",
       "      <td>179.999995</td>\n",
       "      <td>179.999702</td>\n",
       "      <td>19.426512</td>\n",
       "      <td>159.121540</td>\n",
       "      <td>337.252323</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>383.768927</td>\n",
       "      <td>176.781353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            proximal         distal           chi1           chi2  \\\n",
       "count  175521.000000  175521.000000  175521.000000  175521.000000   \n",
       "mean      228.122868     275.877217     -45.297774      -5.662176   \n",
       "std       323.592452     327.258222     104.225509     108.937131   \n",
       "min       -86.000000     -62.000000    -179.999869    -179.999596   \n",
       "25%        42.000000      94.000000     -92.733156     -87.410534   \n",
       "50%       134.000000     188.000000     -64.311525     -54.581797   \n",
       "75%       292.000000     345.000000     -38.734403      96.058493   \n",
       "max      8025.000000    9004.000000     179.999973     179.998744   \n",
       "\n",
       "                chi3           chi4           chi5         energy  \\\n",
       "count  175521.000000  175521.000000  175521.000000  175521.000000   \n",
       "mean       -4.160864     -23.030203     -30.380421       3.736533   \n",
       "std        94.110093     111.367245      99.629063       2.495097   \n",
       "min      -179.981757    -179.999698    -179.999497       0.491737   \n",
       "25%       -87.982527     -97.168156     -74.993066       1.969126   \n",
       "50%       -65.014330     -66.344415     -59.669380       3.189497   \n",
       "75%        92.824530      82.464225      56.393666       4.595320   \n",
       "max       179.994824     179.999995     179.999702      19.426512   \n",
       "\n",
       "         ca_distance    cb_distance   psiprox   phiprox   phidist   psidist  \\\n",
       "count  175521.000000  175521.000000  175521.0  175521.0  175521.0  175521.0   \n",
       "mean        5.684791       3.930672    -180.0    -180.0    -180.0    -180.0   \n",
       "std         1.888242       2.109342       0.0       0.0       0.0       0.0   \n",
       "min         0.000000       0.000000    -180.0    -180.0    -180.0    -180.0   \n",
       "25%         5.160189       3.688707    -180.0    -180.0    -180.0    -180.0   \n",
       "50%         5.714554       3.846127    -180.0    -180.0    -180.0    -180.0   \n",
       "75%         6.268357       4.025268    -180.0    -180.0    -180.0    -180.0   \n",
       "max       159.121540     337.252323    -180.0    -180.0    -180.0    -180.0   \n",
       "\n",
       "       torsion_length            rho  \n",
       "count   175521.000000  175521.000000  \n",
       "mean       232.946064      -0.172521  \n",
       "std         56.621923       8.358270  \n",
       "min         77.516159    -179.997832  \n",
       "25%        185.221894      -1.093180  \n",
       "50%        231.983589       0.015960  \n",
       "75%        272.324025       1.079960  \n",
       "max        383.768927     176.781353  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tors_df1 = Nbuild_torsion_df(ss1, quiet=True)\n",
    "tors_df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proximal</th>\n",
       "      <th>distal</th>\n",
       "      <th>chi1</th>\n",
       "      <th>chi2</th>\n",
       "      <th>chi3</th>\n",
       "      <th>chi4</th>\n",
       "      <th>chi5</th>\n",
       "      <th>energy</th>\n",
       "      <th>ca_distance</th>\n",
       "      <th>cb_distance</th>\n",
       "      <th>phi_prox</th>\n",
       "      <th>psi_prox</th>\n",
       "      <th>phi_dist</th>\n",
       "      <th>psi_dist</th>\n",
       "      <th>torsion_length</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175521.000000</td>\n",
       "      <td>175521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>228.122868</td>\n",
       "      <td>275.877217</td>\n",
       "      <td>-45.297774</td>\n",
       "      <td>-5.662176</td>\n",
       "      <td>-4.160864</td>\n",
       "      <td>-23.030203</td>\n",
       "      <td>-30.380421</td>\n",
       "      <td>3.736533</td>\n",
       "      <td>5.684791</td>\n",
       "      <td>3.930672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.946064</td>\n",
       "      <td>-0.172521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>323.592452</td>\n",
       "      <td>327.258222</td>\n",
       "      <td>104.225509</td>\n",
       "      <td>108.937131</td>\n",
       "      <td>94.110093</td>\n",
       "      <td>111.367245</td>\n",
       "      <td>99.629063</td>\n",
       "      <td>2.495097</td>\n",
       "      <td>1.888242</td>\n",
       "      <td>2.109342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.621923</td>\n",
       "      <td>8.358270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-86.000000</td>\n",
       "      <td>-62.000000</td>\n",
       "      <td>-179.999869</td>\n",
       "      <td>-179.999596</td>\n",
       "      <td>-179.981757</td>\n",
       "      <td>-179.999698</td>\n",
       "      <td>-179.999497</td>\n",
       "      <td>0.491737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.516159</td>\n",
       "      <td>-179.997832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>-92.733156</td>\n",
       "      <td>-87.410534</td>\n",
       "      <td>-87.982527</td>\n",
       "      <td>-97.168156</td>\n",
       "      <td>-74.993066</td>\n",
       "      <td>1.969126</td>\n",
       "      <td>5.160189</td>\n",
       "      <td>3.688707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.221894</td>\n",
       "      <td>-1.093180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>-64.311525</td>\n",
       "      <td>-54.581797</td>\n",
       "      <td>-65.014330</td>\n",
       "      <td>-66.344415</td>\n",
       "      <td>-59.669380</td>\n",
       "      <td>3.189497</td>\n",
       "      <td>5.714554</td>\n",
       "      <td>3.846127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.983589</td>\n",
       "      <td>0.015960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>-38.734403</td>\n",
       "      <td>96.058493</td>\n",
       "      <td>92.824530</td>\n",
       "      <td>82.464225</td>\n",
       "      <td>56.393666</td>\n",
       "      <td>4.595320</td>\n",
       "      <td>6.268357</td>\n",
       "      <td>4.025268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.324025</td>\n",
       "      <td>1.079960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8025.000000</td>\n",
       "      <td>9004.000000</td>\n",
       "      <td>179.999973</td>\n",
       "      <td>179.998744</td>\n",
       "      <td>179.994824</td>\n",
       "      <td>179.999995</td>\n",
       "      <td>179.999702</td>\n",
       "      <td>19.426512</td>\n",
       "      <td>159.121540</td>\n",
       "      <td>337.252323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.768927</td>\n",
       "      <td>176.781353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            proximal         distal           chi1           chi2  \\\n",
       "count  175521.000000  175521.000000  175521.000000  175521.000000   \n",
       "mean      228.122868     275.877217     -45.297774      -5.662176   \n",
       "std       323.592452     327.258222     104.225509     108.937131   \n",
       "min       -86.000000     -62.000000    -179.999869    -179.999596   \n",
       "25%        42.000000      94.000000     -92.733156     -87.410534   \n",
       "50%       134.000000     188.000000     -64.311525     -54.581797   \n",
       "75%       292.000000     345.000000     -38.734403      96.058493   \n",
       "max      8025.000000    9004.000000     179.999973     179.998744   \n",
       "\n",
       "                chi3           chi4           chi5         energy  \\\n",
       "count  175521.000000  175521.000000  175521.000000  175521.000000   \n",
       "mean       -4.160864     -23.030203     -30.380421       3.736533   \n",
       "std        94.110093     111.367245      99.629063       2.495097   \n",
       "min      -179.981757    -179.999698    -179.999497       0.491737   \n",
       "25%       -87.982527     -97.168156     -74.993066       1.969126   \n",
       "50%       -65.014330     -66.344415     -59.669380       3.189497   \n",
       "75%        92.824530      82.464225      56.393666       4.595320   \n",
       "max       179.994824     179.999995     179.999702      19.426512   \n",
       "\n",
       "         ca_distance    cb_distance  phi_prox  psi_prox  phi_dist  psi_dist  \\\n",
       "count  175521.000000  175521.000000       0.0       0.0       0.0       0.0   \n",
       "mean        5.684791       3.930672       NaN       NaN       NaN       NaN   \n",
       "std         1.888242       2.109342       NaN       NaN       NaN       NaN   \n",
       "min         0.000000       0.000000       NaN       NaN       NaN       NaN   \n",
       "25%         5.160189       3.688707       NaN       NaN       NaN       NaN   \n",
       "50%         5.714554       3.846127       NaN       NaN       NaN       NaN   \n",
       "75%         6.268357       4.025268       NaN       NaN       NaN       NaN   \n",
       "max       159.121540     337.252323       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       torsion_length            rho  \n",
       "count   175521.000000  175521.000000  \n",
       "mean       232.946064      -0.172521  \n",
       "std         56.621923       8.358270  \n",
       "min         77.516159    -179.997832  \n",
       "25%        185.221894      -1.093180  \n",
       "50%        231.983589       0.015960  \n",
       "75%        272.324025       1.079960  \n",
       "max        383.768927     176.781353  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tors_df2 = ss1.torsion_df\n",
    "tors_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = [None] * 1000\n",
    "\n",
    "for i in range(1000):\n",
    "    sslist[i] = pdb[i]\n",
    "\n",
    "sslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist2 = DisulfideList(sslist, \"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = DisulfideLoader(verbose=True, subset=True, cutoff=8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = Load_PDB_SS(verbose=True, subset=False, cutoff=8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proteusPy\n",
    "import pickle\n",
    "from proteusPy.logger_config import get_logger\n",
    "\n",
    "_logger = get_logger(\"bootstrap\")\n",
    "\n",
    "\n",
    "def NBootstrap_PDB_SS(\n",
    "    loadpath=DATA_DIR, cutoff=8.0, verbose=False, subset=False, force=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Download and load the disulfide databases from Google Drive.\n",
    "\n",
    "    This function downloads the disulfide databases from Google Drive if they do not\n",
    "    already exist in the specified load path or if the force flag is set to True.\n",
    "    It then loads the disulfide data from the downloaded file and initializes a\n",
    "    DisulfideLoader instance.\n",
    "\n",
    "    :param loadpath: Path from which to load the data, defaults to DATA_DIR\n",
    "    :type loadpath: str\n",
    "    :param cutoff: Cutoff value for disulfide loading, defaults to 8.0\n",
    "    :type cutoff: float\n",
    "    :param verbose: Flag to enable verbose logging, defaults to False\n",
    "    :type verbose: bool\n",
    "    :param subset: Flag to indicate whether to load a subset of the data, defaults to False\n",
    "    :type subset: bool\n",
    "    :param force: Flag to force download even if the file exists, defaults to False\n",
    "    :type force: bool\n",
    "    :return: An instance of DisulfideLoader initialized with the loaded data\n",
    "    :rtype: DisulfideLoader\n",
    "    :raises FileNotFoundError: If the downloaded file is not found\n",
    "    :raises pickle.UnpicklingError: If there is an error unpickling the file\n",
    "    :raises Exception: For any other exceptions that may occur during file loading\n",
    "    \"\"\"\n",
    "    import gdown\n",
    "\n",
    "    fname = SS_PICKLE_FILE\n",
    "    url = SS_LIST_URL\n",
    "\n",
    "    _fname = os.path.join(loadpath, fname)\n",
    "    print(_fname)\n",
    "\n",
    "    if not os.path.exists(_fname) or force is True:\n",
    "        if verbose:\n",
    "            print(\"Downloading Disulfide Database from Drive...\")\n",
    "        gdown.download(url, str(_fname), quiet=False)\n",
    "\n",
    "    full_path = os.path.join(loadpath, _fname)\n",
    "    loader = DisulfideLoader(\n",
    "        datadir=DATA_DIR, subset=subset, verbose=verbose, cutoff=cutoff\n",
    "    )\n",
    "    loader.save(savepath=DATA_DIR, subset=subset, cutoff=cutoff)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NBootstrap_PDB_SS(loadpath=DATA_DIR, verbose=True, subset=True, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = NBootstrap_PDB_SS(loadpath=DATA_DIR, verbose=True, subset=False, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS = Load_PDB_SS(verbose=True, subset=False)\n",
    "PDB_SS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS = Load_PDB_SS(subset=False, verbose=True)\n",
    "PDB_SS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import importlib.resources as pkg_resources\n",
    "\n",
    "# Determine the base directory of the installed package\n",
    "this_dir = Path(pkg_resources.files(\"proteusPy\"))\n",
    "this_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = PDB_SS[0]\n",
    "ss1.rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteusPy import (\n",
    "    torsion_to_sixclass,\n",
    "    torsion_to_eightclass,\n",
    "    torsion_to_class_string,\n",
    ")\n",
    "\n",
    "lhs = [-60, -60, -90, -60, -60]\n",
    "rhs = [60, 60, 90, 60, 60]\n",
    "six = torsion_to_sixclass(lhs)\n",
    "eight = torsion_to_eightclass(lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = torsion_to_class_string(lhs, base=6)\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixr = torsion_to_sixclass(rhs)\n",
    "eightr = torsion_to_eightclass(rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eightr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsion_to_class_string(lhs, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsion_to_class_string(lhs, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disulfide_secondary_structures(pdb_ss):\n",
    "    \"\"\"\n",
    "    Plot a graph of disulfide secondary structures segmented by secondary structure.\n",
    "\n",
    "    :param pdb_ss: The PDB_SS object containing SSList with disulfide bonds.\n",
    "    :type pdb_ss: object\n",
    "    \"\"\"\n",
    "    # Initialize counters for each secondary structure type\n",
    "    helix_count = 0\n",
    "    sheet_count = 0\n",
    "    turn_count = 0\n",
    "    nosecondary_count = 0\n",
    "\n",
    "    # Iterate through the SSList and count the secondary structures\n",
    "    for ss in pdb_ss.SSList:\n",
    "        proximal_secondary = ss.proximal_secondary\n",
    "        distal_secondary = ss.distal_secondary\n",
    "\n",
    "        if proximal_secondary == \"helix\":\n",
    "            helix_count += 1\n",
    "        elif proximal_secondary == \"sheet\":\n",
    "            sheet_count += 1\n",
    "        elif proximal_secondary == \"turn\":\n",
    "            turn_count += 1\n",
    "        elif proximal_secondary == \"nosecondary\":\n",
    "            nosecondary_count += 1\n",
    "\n",
    "        if distal_secondary == \"helix\":\n",
    "            helix_count += 1\n",
    "        elif distal_secondary == \"sheet\":\n",
    "            sheet_count += 1\n",
    "        elif distal_secondary == \"turn\":\n",
    "            turn_count += 1\n",
    "        elif distal_secondary == \"nosecondary\":\n",
    "            nosecondary_count += 1\n",
    "\n",
    "    # Data for plotting\n",
    "    labels = [\"Helix\", \"Sheet\", \"Turn\", \"No Secondary\"]\n",
    "    counts = [helix_count, sheet_count, turn_count, nosecondary_count]\n",
    "\n",
    "    # Plotting the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, counts, color=[\"blue\", \"green\", \"red\", \"gray\"])\n",
    "    plt.xlabel(\"Secondary Structure\")\n",
    "    plt.ylabel(\"Count of Disulfide Bonds\")\n",
    "    plt.title(\"Disulfide Bonds Segmented by Secondary Structure\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_disulfide_secondary_structure_cooccurrence(pdb_ss):\n",
    "    \"\"\"\n",
    "    Plot a graph of disulfide secondary structure co-occurrence by proximal-distal type.\n",
    "\n",
    "    :param pdb_ss: The PDB_SS object containing SSList with disulfide bonds.\n",
    "    :type pdb_ss: object\n",
    "    \"\"\"\n",
    "    # Initialize counters for each proximal-distal secondary structure combination\n",
    "    cooccurrence_counts = {}\n",
    "    skipped = 0\n",
    "    turns = 0\n",
    "    cnt = 0\n",
    "\n",
    "    # Iterate through the SSList and count the secondary structure combinations\n",
    "    for ss in pdb_ss.SSList:\n",
    "        proximal_secondary = ss.proximal_secondary\n",
    "        distal_secondary = ss.distal_secondary\n",
    "        # Skip disulfide bonds with no secondary structure or with a turn secondary structure\n",
    "\n",
    "        if proximal_secondary == \"nosecondary\" or distal_secondary == \"nosecondary\":\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        if proximal_secondary == \"turn\" or distal_secondary == \"turn\":\n",
    "            turns += 1\n",
    "            continue\n",
    "\n",
    "        key = (proximal_secondary, distal_secondary)\n",
    "\n",
    "        if key in cooccurrence_counts:\n",
    "            cooccurrence_counts[key] += 1\n",
    "        else:\n",
    "            cooccurrence_counts[key] = 1\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    print(\n",
    "        f\"Skipped {skipped} disulfide bonds with no secondary structure and {turns} turn secondary structure.\\n\"\n",
    "        f\"Disulfides used: {cnt}\"\n",
    "    )\n",
    "\n",
    "    # Data for plotting\n",
    "    labels = [f\"{prox}-{dist}\" for prox, dist in cooccurrence_counts.keys()]\n",
    "    counts = list(cooccurrence_counts.values())\n",
    "\n",
    "    # Plotting the data\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(labels, counts, color=\"skyblue\")\n",
    "    plt.xlabel(\"Proximal-Distal Secondary Structure\")\n",
    "    plt.ylabel(\"Count of Disulfide Bonds\")\n",
    "    plt.title(\"Co-occurrence of Secondary Structures by Proximal-Distal Type\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_disulfide_secondary_structure_and_rho(pdb_ss):\n",
    "    \"\"\"\n",
    "    Plot a graph of disulfide secondary structure co-occurrence by proximal-distal type\n",
    "    and the disulfide parameter rho with error bars.\n",
    "\n",
    "    :param pdb_ss: The PDB_SS object containing SSList with disulfide bonds.\n",
    "    :type pdb_ss: object\n",
    "    \"\"\"\n",
    "    # Initialize data structures for secondary structure combinations and rho values\n",
    "    cooccurrence_counts = {}\n",
    "    rho_values = {}\n",
    "\n",
    "    # Iterate through the SSList and collect data\n",
    "    for ss in pdb_ss.SSList:\n",
    "        proximal_secondary = ss.proximal_secondary.strip().lower()\n",
    "        distal_secondary = ss.distal_secondary.strip().lower()\n",
    "\n",
    "        # Skip disulfide bonds with no secondary structure or with a turn secondary structure\n",
    "        if proximal_secondary == \"no_secondary\" or distal_secondary == \"no_secondary\":\n",
    "            continue\n",
    "\n",
    "        if proximal_secondary == \"turn\" or distal_secondary == \"turn\":\n",
    "            continue\n",
    "\n",
    "        key = (proximal_secondary, distal_secondary)\n",
    "\n",
    "        if key in cooccurrence_counts:\n",
    "            cooccurrence_counts[key] += 1\n",
    "            rho_values[key].append(ss.ca_distance)\n",
    "        else:\n",
    "            cooccurrence_counts[key] = 1\n",
    "            rho_values[key] = [ss.rho]\n",
    "\n",
    "    # Data for plotting\n",
    "    labels = [f\"{prox}-{dist}\" for prox, dist in cooccurrence_counts.keys()]\n",
    "    counts = list(cooccurrence_counts.values())\n",
    "    rho_means = [np.mean(rho_values[key]) for key in rho_values.keys()]\n",
    "    rho_stds = [np.std(rho_values[key]) for key in rho_values.keys()]\n",
    "\n",
    "    # Plotting the secondary structure co-occurrence\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(labels, counts, color=\"skyblue\")\n",
    "    plt.xlabel(\"Proximal-Distal Secondary Structure\")\n",
    "    plt.ylabel(\"Count of Disulfide Bonds\")\n",
    "    plt.title(\"Co-occurrence of Secondary Structures by Proximal-Distal Type\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the rho values with error bars\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.errorbar(\n",
    "        labels,\n",
    "        rho_means,\n",
    "        yerr=rho_stds,\n",
    "        fmt=\"o\",\n",
    "        color=\"red\",\n",
    "        ecolor=\"black\",\n",
    "        capsize=5,\n",
    "    )\n",
    "    plt.xlabel(\"Proximal-Distal Secondary Structure\")\n",
    "    plt.ylabel(\"Mean Rho Value\")\n",
    "    plt.title(\"Mean Rho Value by Proximal-Distal Secondary Structure with Error Bars\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disulfide_secondary_structure_and_rho(PDB_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disulfide_secondary_structures(PDB_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disulfide_secondary_structure_cooccurrence(PDB_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteusPy import extract_ssbonds_and_atoms\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "verbose = True\n",
    "structure_fname = str(MODEL_DIR / \"pdb5rsa.ent\")\n",
    "ssbond_atom_list, num_ssbonds, errors = extract_ssbonds_and_atoms(\n",
    "    structure_fname, verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"helices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"sheets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"turns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"ssbonds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssbond_atom_list[\"pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "fig = PDB_SS.plot_count_vs_class_df(\n",
    "    df,\n",
    "    title=\"Binary\",\n",
    "    save=True,\n",
    "    savedir=BINARY,\n",
    "    verbose=True,\n",
    "    base=2,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_eightclass_incidence(\n",
    "    theme=\"light\", save=True, verbose=True, savedir=OCTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_sixclass_incidence(\n",
    "    theme=\"light\", save=True, verbose=True, savedir=SEXTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clslist6 = PDB_SS.tclass.sslist_from_classid(\"55555\", base=6)\n",
    "clslist6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clslist8 = PDB_SS.tclass.sslist_from_classid(\"77778\", base=8)\n",
    "clslist8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = PDB_SS.tclass.classdf\n",
    "df6 = PDB_SS.tclass.sixclass_df\n",
    "df8 = PDB_SS.tclass.eightclass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_class_fromlist(loader: DisulfideLoader, sslist):\n",
    "    import pandas as pd\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for cls in sslist:\n",
    "        if cls is not None:\n",
    "            _y = loader.tclass.sslist_from_classid(cls)\n",
    "            # it's possible to have 0 SS in a class\n",
    "            if _y is not None:\n",
    "                # only append if we have both.\n",
    "                x.append(cls)\n",
    "                y.append(len(_y))\n",
    "\n",
    "    sslist_df = pd.DataFrame(columns=[\"class_id\", \"count\"])\n",
    "    sslist_df[\"class_id\"] = x\n",
    "    sslist_df[\"count\"] = y\n",
    "    return sslist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"00000\"\n",
    "sixcls = PDB_SS.tclass.binary_to_six_class(cls)\n",
    "df = enumerate_class_fromlist(PDB_SS, sixcls)\n",
    "# Assuming 'count' is the column by which we want to sort\n",
    "sorted_df = df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"00000\"\n",
    "eightcls = PDB_SS.tclass.binary_to_eight_class(cls)\n",
    "# eightcls\n",
    "\n",
    "df = enumerate_class_fromlist(PDB_SS, eightcls)\n",
    "# Assuming 'count' is the column by which we want to sort\n",
    "sorted_df = df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_eightclass_incidence(theme=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_count_vs_class_df(df, cls, theme=\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_binary_to_sixclass_incidence(light=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight = PDB_SS.tclass.eightclass_df\n",
    "eight.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist2 = PDB_SS.extract_class(\"87784\")\n",
    "sslist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SS.plot_classes_vs_cutoff(0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdict = PDB_SS.SSDict\n",
    "ssdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ss_from_idlist(loader, idlist):\n",
    "    \"\"\"\n",
    "    Return a DisulfideList of Disulfides for a given list of PDBIDs\n",
    "\n",
    "    :param idlist: List of PDBIDs, e.g. ['4yys', '2q7q']\n",
    "    :return: DisulfideList\n",
    "    \"\"\"\n",
    "    res = DisulfideList([], \"RCSB_list\")\n",
    "    for k, v in loader.SSDict.items():\n",
    "        if k in idlist:\n",
    "            for ss_index in range(len(v)):\n",
    "                res.append(loader.SSList[v[ss_index]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = build_ss_from_idlist(PDB_SS, [\"4yys\", \"2q7q\"])\n",
    "sslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = PDB_SS[10:20]\n",
    "slice.pdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = PDB_SS.SSList\n",
    "slice2 = sslist[100:200]\n",
    "slice2.pdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tors = [-60, -60, 90, -60, -60]\n",
    "ss1 = Disulfide(torsions=tors)\n",
    "ss1.pprint_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = PDB_SS[\"2q7q_75D_140D\"]\n",
    "ss1.quiet = False\n",
    "ss1.bond_length_ideality\n",
    "ss1.bond_angle_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihed = ss1.dihedrals\n",
    "modelled_min = Disulfide(\"model\", quiet=False)\n",
    "modelled_min.dihedrals = dihed\n",
    "modelled_min.build_yourself()\n",
    "modelled_min.bond_length_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the distal N->Ca distance. 8/15/24 -egs-\n",
    "\n",
    "modelled_min.bond_angle_ideality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslist = PDB_SS.SSList\n",
    "len(sslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_disulfide_dataframe(disulfide_list):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with columns PDB_ID, SS_Name, Angle_Deviation, Distance_Deviation\n",
    "    from a list of disulfides.\n",
    "\n",
    "    :param disulfide_list: List of disulfide objects.\n",
    "    :type proteusPy.DisulfideList: list\n",
    "    :return: DataFrame containing the disulfide information.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"PDB_ID\": [],\n",
    "        \"SS_Name\": [],\n",
    "        \"Angle_Deviation\": [],\n",
    "        \"Distance_Deviation\": [],\n",
    "        \"Ca_Distance\": [],\n",
    "    }\n",
    "\n",
    "    for ss in tqdm(disulfide_list, desc=\"Processing Disulfides\"):\n",
    "        pdb_id = ss.pdb_id\n",
    "        ca_distance = ss.ca_distance\n",
    "        angle_deviation = ss.bond_angle_ideality\n",
    "        distance_deviation = ss.bond_length_ideality\n",
    "\n",
    "        data[\"PDB_ID\"].append(pdb_id)\n",
    "        data[\"SS_Name\"].append(ss.name)\n",
    "        data[\"Angle_Deviation\"].append(angle_deviation)\n",
    "        data[\"Distance_Deviation\"].append(distance_deviation)\n",
    "        data[\"Ca_Distance\"].append(ca_distance)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a list of disulfide objects called disulfide_list\n",
    "# df = create_disulfide_dataframe(disulfide_list)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = create_disulfide_dataframe(sslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_histograms(df):\n",
    "    \"\"\"\n",
    "    Plot histograms for Distance_Deviation, Angle_Deviation, and Ca_Distance.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(21, 6))\n",
    "\n",
    "    # Distance Deviation Histogram\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(df[\"Distance_Deviation\"], kde=True, bins=30)\n",
    "    plt.title(\"Distance Deviation Distribution\")\n",
    "    plt.xlabel(\"Distance Deviation\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Angle Deviation Histogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.histplot(df[\"Angle_Deviation\"], kde=True, bins=30)\n",
    "    plt.title(\"Angle Deviation Distribution\")\n",
    "    plt.xlabel(\"Angle Deviation\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Ca_Distance Histogram\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.histplot(df[\"Ca_Distance\"], kde=True, bins=30)\n",
    "    plt.title(\"Ca Distance Distribution\")\n",
    "    plt.xlabel(\"Ca Distance\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_histograms(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def highlight_worst_structures(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Highlight the worst structures for distance and angle deviations and annotate their names.\n",
    "    Also, add a subplot showing the worst structures aggregated by PDB_ID.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    :param top_n: Number of worst structures to highlight.\n",
    "    :type top_n: int\n",
    "    \"\"\"\n",
    "    # Identify the worst structures for distance deviation\n",
    "    worst_distance = df.nlargest(top_n, \"Distance_Deviation\")\n",
    "\n",
    "    # Identify the worst structures for angle deviation\n",
    "    worst_angle = df.nlargest(top_n, \"Angle_Deviation\")\n",
    "\n",
    "    # Combine the worst structures\n",
    "    worst_structures = pd.concat([worst_distance, worst_angle]).drop_duplicates()\n",
    "\n",
    "    # Aggregate worst structures by PDB_ID\n",
    "    worst_structures_agg = (\n",
    "        worst_structures.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "    # Scatter plot for all structures\n",
    "    sns.scatterplot(\n",
    "        x=\"Distance_Deviation\",\n",
    "        y=\"Angle_Deviation\",\n",
    "        data=df,\n",
    "        label=\"All Structures\",\n",
    "        ax=axes[0],\n",
    "    )\n",
    "\n",
    "    # Highlight the worst structures\n",
    "    sns.scatterplot(\n",
    "        x=\"Distance_Deviation\",\n",
    "        y=\"Angle_Deviation\",\n",
    "        data=worst_structures,\n",
    "        color=\"red\",\n",
    "        label=\"Worst Structures\",\n",
    "        marker=\"X\",\n",
    "        s=100,\n",
    "        ax=axes[0],\n",
    "    )\n",
    "\n",
    "    # Annotate the worst structures with their names\n",
    "    for i, row in worst_structures.iterrows():\n",
    "        axes[0].annotate(\n",
    "            row[\"SS_Name\"],\n",
    "            (row[\"Distance_Deviation\"], row[\"Angle_Deviation\"]),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(5, 5),\n",
    "            ha=\"right\",\n",
    "        )\n",
    "\n",
    "    axes[0].set_title(\"Distance Deviation vs. Angle Deviation\")\n",
    "    axes[0].set_xlabel(\"Distance Deviation\")\n",
    "    axes[0].set_ylabel(\"Angle Deviation\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Bar plot for worst structures aggregated by PDB_ID\n",
    "    sns.barplot(x=\"PDB_ID\", y=\"Count\", data=worst_structures_agg, ax=axes[1])\n",
    "    axes[1].set_title(\"Worst Structures Aggregated by PDB_ID\")\n",
    "    axes[1].set_xlabel(\"PDB_ID\")\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def highlight_worst_structures2(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Highlight the worst structures for distance and angle deviations and annotate their names.\n",
    "    Also, add subplots showing the worst structures aggregated by PDB_ID for distance and angle deviations.\n",
    "\n",
    "    :param df: DataFrame containing the disulfide information.\n",
    "    :type df: pd.DataFrame\n",
    "    :param top_n: Number of worst structures to highlight.\n",
    "    :type top_n: int\n",
    "    \"\"\"\n",
    "    # Identify the worst structures for distance deviation\n",
    "    worst_distance = df.nlargest(top_n, \"Distance_Deviation\")\n",
    "\n",
    "    # Identify the worst structures for angle deviation\n",
    "    worst_angle = df.nlargest(top_n, \"Angle_Deviation\")\n",
    "\n",
    "    # Combine the worst structures\n",
    "    worst_structures = pd.concat([worst_distance, worst_angle]).drop_duplicates()\n",
    "\n",
    "    # Aggregate worst structures by PDB_ID for distance and angle deviations\n",
    "    worst_distance_agg = (\n",
    "        worst_distance.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "    )\n",
    "    worst_angle_agg = worst_angle.groupby(\"PDB_ID\").size().reset_index(name=\"Count\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "    # Histogram for distance deviation\n",
    "    sns.histplot(df[\"Distance_Deviation\"], kde=True, bins=30, ax=axes[0])\n",
    "    axes[0].set_title(\"Distance Deviation Distribution\")\n",
    "    axes[0].set_xlabel(\"Distance Deviation\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Histogram for angle deviation\n",
    "    sns.histplot(df[\"Angle_Deviation\"], kde=True, bins=30, ax=axes[1])\n",
    "    axes[1].set_title(\"Angle Deviation Distribution\")\n",
    "    axes[1].set_xlabel(\"Angle Deviation\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Bar plots for worst structures aggregated by PDB_ID\n",
    "    sns.barplot(\n",
    "        x=\"PDB_ID\",\n",
    "        y=\"Count\",\n",
    "        data=worst_distance_agg,\n",
    "        ax=axes[2],\n",
    "        color=\"blue\",\n",
    "        label=\"Distance Deviation\",\n",
    "    )\n",
    "    sns.barplot(\n",
    "        x=\"PDB_ID\",\n",
    "        y=\"Count\",\n",
    "        data=worst_angle_agg,\n",
    "        ax=axes[2],\n",
    "        color=\"green\",\n",
    "        label=\"Angle Deviation\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    axes[2].set_title(\"Worst Structures Aggregated by PDB_ID\")\n",
    "    axes[2].set_xlabel(\"PDB_ID\")\n",
    "    axes[2].set_ylabel(\"Count\")\n",
    "    axes[2].tick_params(axis=\"x\", rotation=90)\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# highlight_worst_structures(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_worst_structures2(dev_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_std_cutoff(df, column, num_std=2):\n",
    "    \"\"\"\n",
    "    Calculate cutoff based on standard deviation.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param column: Column name for which to calculate the cutoff.\n",
    "    :type column: str\n",
    "    :param num_std: Number of standard deviations to use for the cutoff.\n",
    "    :type num_std: int\n",
    "    :return: Cutoff value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    cutoff = mean + num_std * std\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def calculate_percentile_cutoff(df, column, percentile=95):\n",
    "    \"\"\"\n",
    "    Calculate cutoff based on percentile.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param column: Column name for which to calculate the cutoff.\n",
    "    :type column: str\n",
    "    :param percentile: Percentile to use for the cutoff.\n",
    "    :type percentile: int\n",
    "    :return: Cutoff value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    cutoff = np.percentile(df[column].dropna(), percentile)\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# distance_cutoff = calculate_percentile_cutoff(dev_df, 'Distance_Deviation', percentile=95)\n",
    "# angle_cutoff = calculate_percentile_cutoff(dev_df, 'Angle_Deviation', percentile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame named dev_df with columns 'Distance_Deviation' and 'Angle_Deviation'\n",
    "\n",
    "# Standard Deviation Method\n",
    "distance_cutoff_std = calculate_std_cutoff(dev_df, \"Distance_Deviation\", num_std=3)\n",
    "angle_cutoff_std = calculate_std_cutoff(dev_df, \"Angle_Deviation\", num_std=3)\n",
    "ca_cutoff_std = calculate_std_cutoff(dev_df, \"Ca_Distance\", num_std=3)\n",
    "\n",
    "# Percentile Method\n",
    "distance_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Distance_Deviation\", percentile=98\n",
    ")\n",
    "angle_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Angle_Deviation\", percentile=98\n",
    ")\n",
    "ca_cutoff_percentile = calculate_percentile_cutoff(dev_df, \"Ca_Distance\", percentile=98)\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (3 Std Dev): {distance_cutoff_std}\")\n",
    "print(f\"Angle Deviation Cutoff (3 Std Dev): {angle_cutoff_std}\")\n",
    "print(f\"Ca Distance Cutoff (3 Std Dev): {ca_cutoff_std}\\n\")\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (98th Percentile): {distance_cutoff_percentile}\")\n",
    "print(f\"Angle Deviation Cutoff (98th Percentile): {angle_cutoff_percentile}\")\n",
    "print(f\"Ca Distance Cutoff (98th Percentile): {ca_cutoff_percentile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_by_cutoffs(df, distance_cutoff, angle_cutoff):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame based on distance and angle cutoffs.\n",
    "\n",
    "    :param df: DataFrame containing the deviations.\n",
    "    :type df: pd.DataFrame\n",
    "    :param distance_cutoff: Cutoff value for distance deviation.\n",
    "    :type distance_cutoff: float\n",
    "    :param angle_cutoff: Cutoff value for angle deviation.\n",
    "    :type angle_cutoff: float\n",
    "    :return: Filtered DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    filtered_df = df[\n",
    "        (df[\"Distance_Deviation\"] <= distance_cutoff)\n",
    "        & (df[\"Angle_Deviation\"] <= angle_cutoff)\n",
    "    ]\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named dev_df\n",
    "# distance_cutoff = 5.0\n",
    "# angle_cutoff = 10.0\n",
    "# filtered_df = filter_by_cutoffs(dev_df, distance_cutoff, angle_cutoff)\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = filter_by_cutoffs(dev_df, 1.0, 10.0)\n",
    "filt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_df[\"Angle_Deviation\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_std_cutoff(df, column, num_std=2):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    cutoff = mean + num_std * std\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def calculate_percentile_cutoff(df, column, percentile=95):\n",
    "    cutoff = np.percentile(df[column].dropna(), percentile)\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "# Assuming you have a DataFrame named dev_df with columns 'Distance_Deviation' and 'Angle_Deviation'\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"Missing values in 'Angle_Deviation': {dev_df['Angle_Deviation'].isna().sum()}\")\n",
    "\n",
    "# Drop missing values for the calculation\n",
    "dev_df = dev_df.dropna(subset=[\"Angle_Deviation\", \"Distance_Deviation\"])\n",
    "\n",
    "# Standard Deviation Method\n",
    "distance_cutoff_std = calculate_std_cutoff(dev_df, \"Distance_Deviation\", num_std=3)\n",
    "angle_cutoff_std = calculate_std_cutoff(dev_df, \"Angle_Deviation\", num_std=3)\n",
    "\n",
    "# Percentile Method\n",
    "distance_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Distance_Deviation\", percentile=98\n",
    ")\n",
    "angle_cutoff_percentile = calculate_percentile_cutoff(\n",
    "    dev_df, \"Angle_Deviation\", percentile=98\n",
    ")\n",
    "\n",
    "print(f\"Distance Deviation Cutoff (3 Std Dev): {distance_cutoff_std}\")\n",
    "print(f\"Angle Deviation Cutoff (3 Std Dev): {angle_cutoff_std}\")\n",
    "print(f\"Distance Deviation Cutoff (98th Percentile): {distance_cutoff_percentile}\")\n",
    "print(f\"Angle Deviation Cutoff (98th Percentile): {angle_cutoff_percentile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppydev (V0.97.8)",
   "language": "python",
   "name": "ppydev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
